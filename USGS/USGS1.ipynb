{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Status Code: 200\n",
      "Number of earthquakes: 19601\n",
      "First earthquake: {'type': 'Feature', 'properties': {'mag': 4.6, 'place': '80 km NW of Kandrian, Papua New Guinea', 'time': 1735602989977, 'updated': 1737523819040, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us6000pgkh', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000pgkh&format=geojson', 'felt': None, 'cdi': None, 'mmi': None, 'alert': None, 'status': 'reviewed', 'tsunami': 0, 'sig': 326, 'net': 'us', 'code': '6000pgkh', 'ids': ',us6000pgkh,', 'sources': ',us,', 'types': ',origin,phase-data,', 'nst': 47, 'dmin': 3.367, 'rms': 0.44, 'gap': 109, 'magType': 'mb', 'type': 'earthquake', 'title': 'M 4.6 - 80 km NW of Kandrian, Papua New Guinea'}, 'geometry': {'type': 'Point', 'coordinates': [148.9729, -5.7603, 127.013]}, 'id': 'us6000pgkh'}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 19601 entries, 2024-12-30 23:56:29.977000 to 2022-04-01 01:08:14.815000\n",
      "Data columns (total 29 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   type       19601 non-null  object \n",
      " 1   id         19601 non-null  object \n",
      " 2   mag        19601 non-null  float64\n",
      " 3   place      19601 non-null  object \n",
      " 4   updated    19601 non-null  int64  \n",
      " 5   tz         0 non-null      object \n",
      " 6   url        19601 non-null  object \n",
      " 7   detail     19601 non-null  object \n",
      " 8   felt       3884 non-null   float64\n",
      " 9   cdi        3884 non-null   float64\n",
      " 10  mmi        2071 non-null   float64\n",
      " 11  alert      1807 non-null   object \n",
      " 12  status     19601 non-null  object \n",
      " 13  tsunami    19601 non-null  int64  \n",
      " 14  sig        19601 non-null  int64  \n",
      " 15  net        19601 non-null  object \n",
      " 16  code       19601 non-null  object \n",
      " 17  ids        19601 non-null  object \n",
      " 18  sources    19601 non-null  object \n",
      " 19  types      19601 non-null  object \n",
      " 20  nst        19021 non-null  float64\n",
      " 21  dmin       19519 non-null  float64\n",
      " 22  rms        19601 non-null  float64\n",
      " 23  gap        19527 non-null  float64\n",
      " 24  magType    19601 non-null  object \n",
      " 25  title      19601 non-null  object \n",
      " 26  latitude   19601 non-null  float64\n",
      " 27  longitude  19601 non-null  float64\n",
      " 28  depth      19601 non-null  float64\n",
      "dtypes: float64(11), int64(3), object(15)\n",
      "memory usage: 4.5+ MB\n",
      "None\n",
      "   OBJECTID           LAYER   Name                       Source PlateA PlateB  \\\n",
      "0         1  plate boundary  AF-AN        Mueller et al. [1987]     AF     AN   \n",
      "1         2  plate boundary  AF-AN  by Peter Bird, October 2001     AF     AN   \n",
      "2         3  plate boundary  AN-AF         Lemaux et al. [2002]     AN     AF   \n",
      "3         4  plate boundary  SO-AN         Lemaux et al. [2002]     SO     AN   \n",
      "4         5  plate boundary  SO-AN        Mueller et al. [1987]     SO     AN   \n",
      "\n",
      "   Type    Shape__Len                                           geometry  \n",
      "0  None  1.283197e+06  LINESTRING Z (-48746.805 -7333156.477 0, -4322...  \n",
      "1  None  2.453129e+06  LINESTRING Z (865214.044 -7245513.558 0, 92265...  \n",
      "2  None  1.703459e+06  LINESTRING Z (3576227.697 -5942041.427 0, 3547...  \n",
      "3  None  1.011037e+06  LINESTRING Z (3576227.697 -5942041.427 0, 3692...  \n",
      "4  None  5.917575e+06  LINESTRING Z (4239346.772 -5561707.664 0, 4251...  \n",
      "Index(['type', 'id', 'mag', 'place', 'updated', 'tz', 'url', 'detail', 'felt',\n",
      "       'cdi', 'mmi', 'alert', 'status', 'tsunami', 'sig', 'net', 'code', 'ids',\n",
      "       'sources', 'types', 'nst', 'dmin', 'rms', 'gap', 'magType', 'title',\n",
      "       'latitude', 'longitude', 'depth', 'geometry', 'index_right', 'OBJECTID',\n",
      "       'LAYER', 'tectonic_plate', 'Source', 'PlateA', 'PlateB', 'Type',\n",
      "       'Shape__Len'],\n",
      "      dtype='object')\n",
      "                               type          id  mag  \\\n",
      "time                                                   \n",
      "2024-12-30 23:56:29.977  earthquake  us6000pgkh  4.6   \n",
      "2024-12-30 23:40:33.868  earthquake  us6000pgkd  4.6   \n",
      "2024-12-30 23:30:59.974  earthquake  us6000pgkb  4.7   \n",
      "2024-12-30 22:13:14.697  earthquake  us6000pgjz  4.8   \n",
      "2024-12-30 20:33:11.322  earthquake  us6000pgjf  4.6   \n",
      "\n",
      "                                                          place  \\\n",
      "time                                                              \n",
      "2024-12-30 23:56:29.977  80 km NW of Kandrian, Papua New Guinea   \n",
      "2024-12-30 23:40:33.868              247 km ENE of Levuka, Fiji   \n",
      "2024-12-30 23:30:59.974           24 km N of Metahāra, Ethiopia   \n",
      "2024-12-30 22:13:14.697             22 km NW of Āwash, Ethiopia   \n",
      "2024-12-30 20:33:11.322            28 km NNW of Āwash, Ethiopia   \n",
      "\n",
      "                               updated    tz  \\\n",
      "time                                           \n",
      "2024-12-30 23:56:29.977  1737523819040  None   \n",
      "2024-12-30 23:40:33.868  1737523683040  None   \n",
      "2024-12-30 23:30:59.974  1737521527845  None   \n",
      "2024-12-30 22:13:14.697  1738203292040  None   \n",
      "2024-12-30 20:33:11.322  1736616791040  None   \n",
      "\n",
      "                                                                       url  \\\n",
      "time                                                                         \n",
      "2024-12-30 23:56:29.977  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
      "2024-12-30 23:40:33.868  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
      "2024-12-30 23:30:59.974  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
      "2024-12-30 22:13:14.697  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
      "2024-12-30 20:33:11.322  https://earthquake.usgs.gov/earthquakes/eventp...   \n",
      "\n",
      "                                                                    detail  \\\n",
      "time                                                                         \n",
      "2024-12-30 23:56:29.977  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "2024-12-30 23:40:33.868  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "2024-12-30 23:30:59.974  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "2024-12-30 22:13:14.697  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "2024-12-30 20:33:11.322  https://earthquake.usgs.gov/fdsnws/event/1/que...   \n",
      "\n",
      "                         felt  cdi  ...                    geometry  \\\n",
      "time                                ...                               \n",
      "2024-12-30 23:56:29.977   NaN  NaN  ...    POINT (148.9729 -5.7603)   \n",
      "2024-12-30 23:40:33.868   NaN  NaN  ...  POINT (-178.3937 -17.6089)   \n",
      "2024-12-30 23:30:59.974   5.0  5.3  ...      POINT (39.9276 9.1189)   \n",
      "2024-12-30 22:13:14.697   6.0  4.3  ...      POINT (40.0367 9.1373)   \n",
      "2024-12-30 20:33:11.322   NaN  NaN  ...      POINT (40.0504 9.2103)   \n",
      "\n",
      "                        index_right OBJECTID  LAYER  tectonic_plate Source  \\\n",
      "time                                                                         \n",
      "2024-12-30 23:56:29.977         NaN      NaN    NaN             NaN    NaN   \n",
      "2024-12-30 23:40:33.868         NaN      NaN    NaN             NaN    NaN   \n",
      "2024-12-30 23:30:59.974         NaN      NaN    NaN             NaN    NaN   \n",
      "2024-12-30 22:13:14.697         NaN      NaN    NaN             NaN    NaN   \n",
      "2024-12-30 20:33:11.322         NaN      NaN    NaN             NaN    NaN   \n",
      "\n",
      "                        PlateA PlateB Type Shape__Len  \n",
      "time                                                   \n",
      "2024-12-30 23:56:29.977    NaN    NaN  NaN        NaN  \n",
      "2024-12-30 23:40:33.868    NaN    NaN  NaN        NaN  \n",
      "2024-12-30 23:30:59.974    NaN    NaN  NaN        NaN  \n",
      "2024-12-30 22:13:14.697    NaN    NaN  NaN        NaN  \n",
      "2024-12-30 20:33:11.322    NaN    NaN  NaN        NaN  \n",
      "\n",
      "[5 rows x 39 columns]\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 19601 entries, 0 to 19600\n",
      "Data columns (total 46 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   time             19601 non-null  datetime64[ns]\n",
      " 1   type             19601 non-null  object        \n",
      " 2   id               19601 non-null  object        \n",
      " 3   mag              19601 non-null  float64       \n",
      " 4   place            19601 non-null  object        \n",
      " 5   updated          19601 non-null  int64         \n",
      " 6   tz               19601 non-null  int64         \n",
      " 7   url              19601 non-null  object        \n",
      " 8   detail           19601 non-null  object        \n",
      " 9   felt             19601 non-null  float64       \n",
      " 10  cdi              19601 non-null  float64       \n",
      " 11  mmi              19601 non-null  float64       \n",
      " 12  alert            19601 non-null  object        \n",
      " 13  status           19601 non-null  object        \n",
      " 14  tsunami          19601 non-null  int64         \n",
      " 15  sig              19601 non-null  int64         \n",
      " 16  net              19601 non-null  object        \n",
      " 17  code             19601 non-null  object        \n",
      " 18  ids              19601 non-null  object        \n",
      " 19  sources          19601 non-null  object        \n",
      " 20  types            19601 non-null  object        \n",
      " 21  nst              19601 non-null  float64       \n",
      " 22  dmin             19601 non-null  float64       \n",
      " 23  rms              19601 non-null  float64       \n",
      " 24  gap              19601 non-null  float64       \n",
      " 25  magType          19601 non-null  object        \n",
      " 26  title            19601 non-null  object        \n",
      " 27  latitude         19601 non-null  float64       \n",
      " 28  longitude        19601 non-null  float64       \n",
      " 29  depth            19601 non-null  float64       \n",
      " 30  geometry         19601 non-null  geometry      \n",
      " 31  index_right      19601 non-null  float64       \n",
      " 32  OBJECTID         19601 non-null  float64       \n",
      " 33  LAYER            19601 non-null  int64         \n",
      " 34  tectonic_plate   19601 non-null  int64         \n",
      " 35  Source           19601 non-null  int64         \n",
      " 36  PlateA           19601 non-null  int64         \n",
      " 37  PlateB           19601 non-null  int64         \n",
      " 38  Type             19601 non-null  int64         \n",
      " 39  Shape__Len       19601 non-null  float64       \n",
      " 40  time_since_last  19601 non-null  float64       \n",
      " 41  count_1m         19601 non-null  int64         \n",
      " 42  count_3m         19601 non-null  int64         \n",
      " 43  count_6m         19601 non-null  int64         \n",
      " 44  rolling_avg      19601 non-null  float64       \n",
      " 45  rolling_avg_3m   19601 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(17), geometry(1), int64(13), object(14)\n",
      "memory usage: 6.9+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_9828\\3224999938.py:129: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gdf.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "# Set Up the URL \n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "params = {\n",
    "    \"format\": \"geojson\",\n",
    "    \"starttime\": \"2022-04-01\",\n",
    "    \"endtime\": \"2024-12-31\",\n",
    "    \"minmagnitude\": 4.5,\n",
    "}\n",
    "\n",
    "# Send the Request and Check the Response\n",
    "response = requests.get(url, params=params)\n",
    "print(f\"Response Status Code: {response.status_code}\")\n",
    "if response.status_code == 200:\n",
    "    earthquake_data = response.json()\n",
    "    print(\"Number of earthquakes:\", len(earthquake_data[\"features\"]))\n",
    "    print(\"First earthquake:\", earthquake_data[\"features\"][0])\n",
    "elif response.status_code == 400:\n",
    "    print(\"Bad Request Error: Check URL and parameters\")\n",
    "    print(response.text)  # Print the full response text for debugging\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n",
    "\n",
    "# Ensure the DataFrame df is only created if the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the GeoJSON Data and Extract Information\n",
    "    earthquake_list = []\n",
    "    for feature in earthquake_data[\"features\"]:\n",
    "        earthquake = {\n",
    "            \"type\": feature[\"type\"],\n",
    "            \"geometry\": feature[\"geometry\"],\n",
    "            \"id\": feature[\"id\"]\n",
    "        }\n",
    "        for key, value in feature[\"properties\"].items():\n",
    "            earthquake[key] = value\n",
    "        earthquake_list.append(earthquake)\n",
    "    df = pd.DataFrame(earthquake_list)\n",
    "else:\n",
    "    print(\"DataFrame 'df' is not defined. Check for issues in the data extraction steps.\")\n",
    "\n",
    "# Extract Latitude, Longitude, and Depth from geometry\n",
    "if 'df' in locals():\n",
    "    df['latitude'] = df['geometry'].apply(lambda x: x['coordinates'][1])\n",
    "    df['longitude'] = df['geometry'].apply(lambda x: x['coordinates'][0])\n",
    "    df['depth'] = df['geometry'].apply(lambda x: x['coordinates'][2])\n",
    "\n",
    "    # Convert Timestamp to Datetime\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "\n",
    "    # Drop the geometry column if no longer needed\n",
    "    df.drop(columns=['geometry'], inplace=True)\n",
    "\n",
    "    # Set 'time' as the index\n",
    "    df.set_index('time', inplace=True)\n",
    "\n",
    "    # Display DataFrame information\n",
    "    print(df.info())\n",
    "else:\n",
    "    print(\"DataFrame 'df' is not defined. Check for issues in the data extraction steps.\")\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "def create_geodataframe(df):\n",
    "    geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "    return gdf\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "gdf = create_geodataframe(df)\n",
    "\n",
    "# Set Coordinate Reference System (CRS)\n",
    "gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# Path to the extracted shapefile directory\n",
    "extract_to_path = r'C:\\Users\\thoma\\Documents\\GitHub\\USGS\\Tectonic_Plates_and_Boundaries'\n",
    "shapefile_path = os.path.join(extract_to_path, 'Tectonic_Plates_and_Boundaries.shp')\n",
    "\n",
    "# Load the shapefile using GeoPandas\n",
    "if os.path.exists(shapefile_path):\n",
    "    tectonic_plates = gpd.read_file(shapefile_path)\n",
    "    print(tectonic_plates.head())\n",
    "else:\n",
    "    print(\"Shapefile not found. Please check the path.\")\n",
    "\n",
    "# Ensure the tectonic plates GeoDataFrame has the same CRS as the earthquake GeoDataFrame\n",
    "tectonic_plates = tectonic_plates.to_crs(gdf.crs)\n",
    "\n",
    "# Perform spatial join to associate each earthquake with the corresponding tectonic plate\n",
    "gdf = gpd.sjoin(gdf, tectonic_plates, how='left', predicate='intersects', lsuffix='left', rsuffix='right')\n",
    "\n",
    "# Rename the column for clarity\n",
    "gdf.rename(columns={'Name': 'tectonic_plate'}, inplace=True)\n",
    "\n",
    "# Verify the results of the renaming\n",
    "print(gdf.columns)\n",
    "print(gdf.head())\n",
    "\n",
    "# Ensure 'time' column is retained for feature engineering\n",
    "gdf.reset_index(inplace=True)\n",
    "\n",
    "# Calculate time since last significant earthquake within each tectonic plate\n",
    "gdf['time_since_last'] = gdf.groupby('tectonic_plate')['time'].diff().dt.days\n",
    "\n",
    "# Define function to count earthquakes within specified days\n",
    "def count_earthquakes(df, days):\n",
    "    end_date = df['time'].max()\n",
    "    start_date = end_date - pd.Timedelta(days=days)\n",
    "    filtered_df = df[(df['time'] >= start_date) & (df['time'] <= end_date)]\n",
    "    return filtered_df.groupby('tectonic_plate')['mag'].count()\n",
    "\n",
    "# Count number of smaller earthquakes in past 1, 3, and 6 months within each tectonic plate\n",
    "gdf['count_1m'] = gdf.apply(lambda row: count_earthquakes(gdf[gdf['tectonic_plate'] == row['tectonic_plate']], 30).get(row['tectonic_plate'], 0), axis=1)\n",
    "gdf['count_3m'] = gdf.apply(lambda row: count_earthquakes(gdf[gdf['tectonic_plate'] == row['tectonic_plate']], 90).get(row['tectonic_plate'], 0), axis=1)\n",
    "gdf['count_6m'] = gdf.apply(lambda row: count_earthquakes(gdf[gdf['tectonic_plate'] == row['tectonic_plate']], 180).get(row['tectonic_plate'], 0), axis=1)\n",
    "\n",
    "# Rolling averages of seismic activity within each tectonic plate\n",
    "def rolling_avg_earthquakes(df, days):\n",
    "    df['rolling_avg'] = df.groupby('tectonic_plate')['mag'].transform(lambda x: x.rolling(window=days, min_periods=1).mean())\n",
    "    return df['rolling_avg']\n",
    "\n",
    "gdf['rolling_avg_3m'] = rolling_avg_earthquakes(gdf, 90)\n",
    "\n",
    "# Fill NA values with appropriate values (e.g., 0 for counts)\n",
    "gdf.fillna(0, inplace=True)\n",
    "\n",
    "# Display DataFrame information\n",
    "print(gdf.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "features = ['time_since_last', 'count_1m', 'count_3m', 'count_6m', 'rolling_avg_3m', 'latitude', 'longitude']\n",
    "threshold_magnitude = 6.0  # Define your threshold magnitude\n",
    "X = gdf[features]\n",
    "y = (gdf['mag'] >= threshold_magnitude).astype(int)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.981\n",
      "Logistic Regression ROC-AUC Score: 0.454\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "y_prob_log_reg = log_reg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "roc_auc_log_reg = roc_auc_score(y_test, y_prob_log_reg)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", round(accuracy_log_reg, 3))\n",
    "print(\"Logistic Regression ROC-AUC Score:\", round(roc_auc_log_reg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.967\n",
      "Decision Tree ROC-AUC Score: 0.506\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = decision_tree_model.predict(X_test)\n",
    "y_prob_dt = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Decision Tree model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_test, y_prob_dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", round(accuracy_dt, 3))\n",
    "print(\"Decision Tree ROC-AUC Score:\", round(roc_auc_dt, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.973\n",
      "Gradient Boosting ROC-AUC Score: 0.531\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "y_prob_gb = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "roc_auc_gb = roc_auc_score(y_test, y_prob_gb)\n",
    "\n",
    "print(\"Gradient Boosting Accuracy:\", round(accuracy_gb, 3))\n",
    "print(\"Gradient Boosting ROC-AUC Score:\", round(roc_auc_gb, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.981\n",
      "CatBoost ROC-AUC Score: 0.587\n"
     ]
    }
   ],
   "source": [
    "# Train the CatBoost model\n",
    "catboost_model = CatBoostClassifier(iterations=100, random_state=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cb = catboost_model.predict(X_test)\n",
    "y_prob_cb = catboost_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the CatBoost model\n",
    "accuracy_cb = accuracy_score(y_test, y_pred_cb)\n",
    "roc_auc_cb = roc_auc_score(y_test, y_prob_cb)\n",
    "\n",
    "print(\"CatBoost Accuracy:\", round(accuracy_cb, 3))\n",
    "print(\"CatBoost ROC-AUC Score:\", round(roc_auc_cb, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 255, number of negative: 15425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 15680, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.016263 -> initscore=-4.102481\n",
      "[LightGBM] [Info] Start training from score -4.102481\n",
      "LightGBM Accuracy: 0.981\n",
      "LightGBM ROC-AUC Score: 0.578\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['time_since_last', 'count_1m', 'count_3m', 'count_6m', 'rolling_avg_3m', 'latitude', 'longitude']\n",
    "X = gdf[features]\n",
    "y = (gdf['mag'] >= 6.0).astype(int)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgbm_model = LGBMClassifier(n_estimators=100, random_state=42)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "y_prob_lgbm = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the LightGBM model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "roc_auc_lgbm = roc_auc_score(y_test, y_prob_lgbm)\n",
    "\n",
    "print(\"LightGBM Accuracy:\", round(accuracy_lgbm, 3))\n",
    "print(\"LightGBM ROC-AUC Score:\", round(roc_auc_lgbm, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
